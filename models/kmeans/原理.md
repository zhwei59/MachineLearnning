## Kmeans原理

### 前提假设
数据之间的相似度用欧氏距离量衡量，如果不是欧氏距离，要转化成欧氏距离。

余弦相似度，欧氏距离和杰卡德相似度
- 余弦相似度强调的是方向，两者的夹角越接近0度，越相似，考虑的趋势。
- 欧氏距离强调的是空间点之间的距离，所以虽然两者方向上可能一致，但是距离相差甚远。
- 余弦相似度用在用户兴趣表示上，欧氏距离用在用户价值表示上。
- 杰卡德相似度强调的是集合中的同现度。杰卡德距离通过两个集合中不同元素的比例来表示区分度。

### 算法讲解
k-means是无监督模型，将样本按照给定的k进行分类。
### 伪代码

``` python

sample=[d1,d2,d3,d4]
karr=[k1,k2,k3]
newkarr=[[],[],[]]
dis=sys.maxint
while dis<阈值
for d in sample:
    ck=0
    mink=sys.maxint
    for i,k in enumerator(karr):
        if od(d,k)<mink:
            ck=i
            mink=k
    for v,v in d:
        newk[ck][j]+=v
dis=od(karr,newk)




```
